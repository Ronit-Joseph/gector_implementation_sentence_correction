{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7410882e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronit/miniconda3/envs/gector_env/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ronit/miniconda3/envs/gector_env/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from gector.gec_model import GecBERTModel\n",
    "\n",
    "# Create an instance of the model\n",
    "model = GecBERTModel(vocab_path = \"./data/output_vocabulary\", model_paths = [\"./gector/roberta-large_1_pie_1bw_st3.th\"])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0e2d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add the sentence with grammatical errors\n",
    "sent = 'hey guys hows it going my names george'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8f9081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey', 'guys', 'hows', 'it', 'going', 'my', 'names', 'george']\n",
      "['Hey', 'guys', ',', 'how', 'is', 'it', 'going', '?', 'My', 'name', 'is', 'George']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the words \n",
    "batch = []\n",
    "batch.append(sent.split())\n",
    "#temp printing batch-teh list of sentence with errors\n",
    "for i in range(len(batch)):\n",
    "    print(batch[i])\n",
    "#temp printing final batch - the list of corrected sentence  \n",
    "final_batch, total_updates = model.handle_batch(batch)\n",
    "#temp\n",
    "for i in range(len(final_batch)):\n",
    "    print(final_batch[i])\n",
    "    print(total_updates)\n",
    "#temp\n",
    "updated_sent = \" \".join(final_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ecba802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_dict(input_sentence, corrected_sentence):\n",
    "    output_dict_list = []\n",
    "    end_index = -2\n",
    "    i = 0\n",
    "    j = i\n",
    "    while i < len(input_sentence) and j<len(corrected_sentence):\n",
    "        original_word = input_sentence[i]\n",
    "        corrected_word = corrected_sentence[j]\n",
    "\n",
    "        if original_word.lower() == corrected_word.lower():\n",
    "            start_index = end_index + 2\n",
    "            end_index = start_index\n",
    "            end_index += len(corrected_word) \n",
    "            output_dict = {\n",
    "                'word': original_word,\n",
    "                'correction': corrected_word,\n",
    "                'start_index': start_index,\n",
    "                'end_index': end_index,\n",
    "            }\n",
    "            if(original_word != corrected_word):\n",
    "                output_dict_list.append(output_dict)\n",
    "            i += 1\n",
    "            j += 1\n",
    "            continue\n",
    "        \n",
    "        # Check up to 3 tokens in the corrected sentence for correction\n",
    "        correction_tokens = []\n",
    "        k = j+2\n",
    "        while j < min(k, len(corrected_sentence)):\n",
    "            correction_tokens.append(corrected_sentence[j])\n",
    "            if original_word.lower() == corrected_sentence[j].lower():\n",
    "                j += 1\n",
    "                break\n",
    "            j += 1\n",
    "            \n",
    "\n",
    "        correction = ' '.join(correction_tokens) if any(correction_tokens) else None\n",
    "\n",
    "        start_index = end_index\n",
    "        end_index = start_index + len(correction)\n",
    "\n",
    "        output_dict = {\n",
    "            'word': original_word,\n",
    "            'correction': correction,\n",
    "            'start_index': start_index,\n",
    "            'end_index': end_index,\n",
    "        }\n",
    "        output_dict_list.append(output_dict)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # while(i<len(input_sentence)):\n",
    "        \n",
    "    return output_dict_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7696ba41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'hey', 'correction': 'Hey', 'start_index': 0, 'end_index': 3}\n",
      "{'word': 'hows', 'correction': ', how', 'start_index': 9, 'end_index': 14}\n",
      "{'word': 'it', 'correction': 'is it', 'start_index': 14, 'end_index': 19}\n",
      "{'word': 'my', 'correction': '? My', 'start_index': 26, 'end_index': 30}\n",
      "{'word': 'names', 'correction': 'name is', 'start_index': 30, 'end_index': 37}\n",
      "{'word': 'george', 'correction': 'George', 'start_index': 39, 'end_index': 45}\n"
     ]
    }
   ],
   "source": [
    "# input_sentence = ['hey', 'guys', 'hows', 'it', 'going', 'my', 'names', 'george']\n",
    "# corrected_sentence = ['Hey', 'guys', ',', 'how', 'is', 'it', 'going', '?', 'My', 'name', 'is', 'George']\n",
    "\n",
    "output_dict_list = generate_output_dict(batch[0], final_batch[0])\n",
    "\n",
    "# Print the output\n",
    "for output_dict in output_dict_list:\n",
    "    print(output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd7d4474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: hey guys hows it going my names george\n",
      "\n",
      "Updated Sentence: Hey guys , how is it going ? My name is George\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original Sentence: {sent}\\n\")\n",
    "print(f\"Updated Sentence: {updated_sent}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gector_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
